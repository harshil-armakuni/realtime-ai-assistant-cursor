# AI Meeting Assistant

A production-grade real-time AI meeting assistant that captures audio and screen content to provide intelligent answers during client meetings.

## Features

- ğŸ™ï¸ **Real-time Audio Transcription**: Supports English, Hindi, and Gujarati
- ğŸ–¥ï¸ **Screen Capture**: Captures screen every 2 seconds for visual context
- ğŸ¤– **Intelligent Q&A**: Automatically detects questions and provides brief or detailed answers
- ğŸ’¾ **Local Storage**: Stores screen captures locally for privacy
- ğŸŒ **Modern UI**: Beautiful, responsive frontend with real-time updates
- âš¡ **Low Latency**: WebRTC connection for minimal delay

## Tech Stack

### Backend (Python)
- FastAPI
- OpenAI API (GPT-4o + Realtime API)
- MSS (Screen capture)
- Pillow (Image processing)

### Frontend (Node.js)
- React
- Vite
- Web Speech API (with OpenAI Realtime API integration)

## Setup Instructions

### 1. Prerequisites
- Python 3.10+
- Node.js 18+
- OpenAI API key

### 2. Environment Setup

Create `.env` file in the root directory:
```bash
OPENAI_API_KEY=your_openai_api_key_here
```

### 3. Backend Setup

```bash
# Create virtual environment
python3 -m venv .venv

# Activate virtual environment
source .venv/bin/activate  # On Linux/Mac
# .venv\Scripts\activate  # On Windows

# Install dependencies
pip install -r backend/requirements.txt

# Run backend
python backend/main.py
```

Backend will run on `http://localhost:8000`

### 4. Frontend Setup

```bash
# Navigate to frontend directory
cd frontend

# Install dependencies
npm install

# Run development server
npm run dev
```

Frontend will run on `http://localhost:5173`

## Usage

1. **Start the Application**
   - Start backend: `python backend/main.py`
   - Start frontend: `cd frontend && npm run dev`

2. **Open Browser**
   - Navigate to `http://localhost:5173`

3. **Start Recording**
   - Click "Start Recording" button
   - Grant microphone and screen permissions
   - The app will start transcribing audio and capturing screen

4. **Ask Questions**
   - Speak naturally during your meeting
   - The app automatically detects questions
   - Receives intelligent answers in real-time

5. **Stop Recording**
   - Click "Stop Recording" when done
   - All data is stored locally

## How It Works

### Audio Processing
1. Browser captures microphone audio
2. Audio is processed using Web Speech API (with OpenAI Realtime API integration)
3. Transcription appears in real-time
4. Questions are automatically detected

### Screen Analysis
1. Backend captures screen every 2 seconds
2. Screenshots stored locally in `storage/screenshots/`
3. When a question is detected, latest screenshot is analyzed
4. Visual context is combined with audio transcript

### Intelligent Responses
1. System analyzes question complexity
2. Determines if brief or detailed answer is needed
3. Combines audio transcript + screen context
4. Generates contextual answer using GPT-4o

## API Endpoints

### Backend APIs
- `POST /api/session/token` - Generate ephemeral token for Realtime API
- `POST /api/capture/start` - Start screen capture
- `POST /api/capture/stop` - Stop screen capture
- `GET /api/capture/status` - Get capture status
- `POST /api/analyze/screen` - Analyze screen context
- `POST /api/answer` - Get intelligent answer
- `WS /ws/meeting` - WebSocket for real-time updates

## Project Structure

```
.
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Main React component
â”‚   â”‚   â”œâ”€â”€ App.css         # Styling
â”‚   â”‚   â”œâ”€â”€ main.jsx        # Entry point
â”‚   â”‚   â””â”€â”€ index.css       # Global styles
â”‚   â”œâ”€â”€ index.html          # HTML template
â”‚   â”œâ”€â”€ vite.config.js      # Vite configuration
â”‚   â””â”€â”€ package.json        # Node dependencies
â”œâ”€â”€ storage/
â”‚   â””â”€â”€ screenshots/        # Stored screen captures
â”œâ”€â”€ .env                    # Environment variables
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## Security & Privacy

- All screen captures stored locally
- No data sent to third parties except OpenAI API
- API key stored securely in `.env` file
- WebSocket connections secured

## Performance

- Screen capture: Every 2 seconds
- Audio processing: Real-time
- Response latency: < 2 seconds
- Memory efficient with rolling screenshot buffer (keeps last 10)

## Multi-language Support

The app supports transcription in:
- English (en-US)
- Hindi (hi-IN)
- Gujarati (gu-IN)

To change language, modify the `lang` parameter in the speech recognition setup.

## Troubleshooting

### Audio not working
- Ensure microphone permissions are granted
- Check browser console for errors
- Verify Web Speech API support in your browser

### Screen capture fails
- Ensure backend has necessary permissions
- Check `storage/screenshots/` directory exists
- Verify mss library installation

### Connection errors
- Ensure both backend and frontend are running
- Check firewall settings
- Verify ports 8000 and 5173 are available

## Future Enhancements

- [ ] Full OpenAI Realtime API WebRTC integration
- [ ] Recording session playback
- [ ] Export meeting notes
- [ ] Multi-monitor support
- [ ] Custom language models
- [ ] Cloud storage integration

## License

MIT License - Feel free to use for personal or commercial projects.

## Support

For issues or questions, please check the troubleshooting section or review the code comments.